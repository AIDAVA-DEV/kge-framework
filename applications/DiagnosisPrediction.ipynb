{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shervin/opt/anaconda3/envs/AIDAVA/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import  torch\n",
    "from    torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..') # set directoroy to AIDAVA-KGE-Framework (run once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  pickle \n",
    "\n",
    "from    src.rgnn import RGCNEncoder\n",
    "\n",
    "import  torch.nn.functional as F\n",
    "import  tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path   = './data/m2skg/'\n",
    "filename    = 'relation_train.pkl'\n",
    "\n",
    "node_embed_dim  = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path+filename,'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = dict({})\n",
    "node_count = 0 \n",
    "\n",
    "relations = dict({})\n",
    "rel_count = 0 \n",
    "\n",
    "triples = []\n",
    "\n",
    "for h,r,t in data:\n",
    "\n",
    "    if h not in nodes.keys():\n",
    "        nodes[h] = node_count\n",
    "        node_count += 1\n",
    "\n",
    "    if t not in nodes.keys():\n",
    "        nodes[t] = node_count\n",
    "        node_count += 1\n",
    "\n",
    "    if r not in relations.keys():\n",
    "        relations[r] = rel_count \n",
    "        rel_count += 1 \n",
    "\n",
    "    triples.append( ( nodes[h],relations[r] , nodes[t] ) )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 3574, 10133)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_count , node_count, len(triples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triples[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TransE for Link Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from    src.TransE import TransE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_e = TransE(num_entities = node_count,\n",
    "       num_relations = rel_count,\n",
    "       device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shervin/Documents/AIDAVA/aidava-kge-framework/src/loaders.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(self.edges_index[idx][0]), self.edges_index[idx][1],   torch.tensor(self.edges_index[idx][2]), torch.tensor(neg_sample[0][0]) , torch.tensor(neg_sample[1]) , torch.tensor(neg_sample[0][1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0,\t train loss 0.99\n",
      "epoch 10,\t train loss 0.73\n",
      "epoch 20,\t train loss 0.63\n",
      "epoch 30,\t train loss 0.58\n",
      "epoch 40,\t train loss 0.56\n",
      "epoch 50,\t train loss 0.53\n",
      "epoch 60,\t train loss 0.52\n",
      "epoch 70,\t train loss 0.52\n",
      "epoch 80,\t train loss 0.51\n",
      "epoch 90,\t train loss 0.50\n"
     ]
    }
   ],
   "source": [
    "trans_e._train(triples);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hits@1 0.47 hits@10 0.89  MR 4.78 MRR  0.61\n"
     ]
    }
   ],
   "source": [
    "trans_e._eval(triples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIDAVA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
